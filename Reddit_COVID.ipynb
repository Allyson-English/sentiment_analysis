{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import textblob as textblob\n",
    "import praw\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import creds\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing NLTK library and associated packaged\n",
    "\n",
    "import nltk\n",
    "nltk.__version__\n",
    "# nltk.download('vader_lexicon')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import pos_tag_sents\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "#Importing textblob to compare sentiment analysis results with those from nltk\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reddit API wrapper \n",
    "\n",
    "reddit = praw.Reddit(client_id=creds.client_id, \\\n",
    "                     client_secret=creds.client_secret, \\\n",
    "                     user_agent=creds.user_agent, \\\n",
    "                     username=creds.username, \\\n",
    "                     password=creds.password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting daily ID for the Coronavirus daily discussion post\n",
    "\n",
    "subreddit = reddit.subreddit('Coronavirus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ghnx5y\n"
     ]
    }
   ],
   "source": [
    "#Gets discussion id for that days daily discussion\n",
    "\n",
    "discussion_id = str(list(subreddit.hot(limit=1)))\n",
    "final_id = discussion_id.replace(\"[Submission(id='\",\"\").replace(\"')]\",\"\")\n",
    "print(final_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "#pulls all discussion ids available \n",
    "\n",
    "discussion_ids = []\n",
    "\n",
    "for submission in subreddit.search('Daily Discussion Post'):\n",
    "    if 'Daily Discussion Post' in submission.title:\n",
    "        discussion_ids.append(submission.id)\n",
    "    \n",
    "print(len(discussion_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r\"/Users/AllysonEnglish/Active/Active/coronavirus_subreddit_full.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coronavirus_new_comments(json_file_path, discussion_ids, reddit = reddit):\n",
    "    \n",
    "    with open(json_file_path, \"r\") as f:\n",
    "        full_comment_dict = json.load(f)\n",
    "\n",
    "    st = time()\n",
    "\n",
    "    print(\"There are\", len(discussion_ids), \"daily discussions to grab comments from.\\n\")\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for disc_id in discussion_ids:\n",
    "        disc_dict = {}      \n",
    "\n",
    "        submission = reddit.submission(disc_id)    \n",
    "        submission.comments.replace_more(limit=0)\n",
    "\n",
    "        print(disc_id, \" number of comments:  \", len(submission.comments))\n",
    "        \n",
    "        if disc_id not in full_comment_dict.keys():\n",
    "            full_comment_dict[disc_id] = {}\n",
    "\n",
    "        for user_comment in submission.comments:\n",
    "\n",
    "            if str(user_comment) not in full_comment_dict[disc_id].keys():\n",
    "\n",
    "                #submission.comments.replace_more(limit=0)\n",
    "                comment = user_comment.body\n",
    "                comment = comment.replace('\\n', ' ')\n",
    "                comment = comment.replace('I\\'m', 'i am').replace('i\\'m', 'i am').replace('i\\'ll', 'i will').replace('I\\'ll', 'i will')\n",
    "                comment = comment.lower()\n",
    "\n",
    "                #grab date/ time info for each comment \n",
    "                utc = submission.created_utc\n",
    "                dt_object = datetime.fromtimestamp(utc)  \n",
    "\n",
    "                #performing sentiment analysis\n",
    "                ss = sid.polarity_scores(comment)\n",
    "\n",
    "\n",
    "                token_dict = {\"comment_body\" : comment}\n",
    "                token_dict.update({\"month\":dt_object.strftime(\"%B\")})\n",
    "                token_dict.update({\"day\" : dt_object.strftime(\"%d\")})\n",
    "                token_dict.update(ss)\n",
    "                disc_dict.update({str(user_comment): token_dict})\n",
    "\n",
    "                full_comment_dict.update({disc_id: disc_dict})\n",
    "\n",
    "    #update json file with new comments\n",
    "    with open(json_file_path, \"w\") as outfile:\n",
    "        json.dump(full_comment_dict, outfile, indent = 4)\n",
    "\n",
    "    print(\"\\nProcessing time:\", round((time()-st)/60, 2), \"minutes.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 85 daily discussions to grab comments from.\n",
      "\n",
      "gh1uuu  number of comments:   112\n",
      "gftmeo  number of comments:   127\n",
      "ghnx5y  number of comments:   107\n",
      "gekees  number of comments:   135\n",
      "ggfrvq  number of comments:   112\n",
      "gf6xnu  number of comments:   120\n",
      "gdbzvl  number of comments:   123\n",
      "gdy3p3  number of comments:   134\n",
      "ga9u7y  number of comments:   148\n",
      "gcqx67  number of comments:   116\n",
      "gaw27w  number of comments:   143\n",
      "g8eo6c  number of comments:   172\n",
      "gbih0c  number of comments:   125\n",
      "g912p1  number of comments:   176\n",
      "gc6tdq  number of comments:   116\n",
      "g61hda  number of comments:   178\n",
      "fjla5p  number of comments:   356\n",
      "g7tugs  number of comments:   167\n",
      "flad2s  number of comments:   334\n",
      "g9nks9  number of comments:   120\n",
      "g6n0i9  number of comments:   158\n",
      "g5fli1  number of comments:   188\n",
      "fvz4b2  number of comments:   232\n",
      "g32elm  number of comments:   177\n",
      "g3nu29  number of comments:   157\n",
      "fj1m3e  number of comments:   356\n",
      "ftmp3u  number of comments:   256\n",
      "fmfa26  number of comments:   332\n",
      "g47znm  number of comments:   166\n",
      "g15wnp  number of comments:   193\n",
      "fsd9v4  number of comments:   254\n",
      "g2fafj  number of comments:   186\n",
      "fn0a59  number of comments:   283\n",
      "g1sbbp  number of comments:   191\n",
      "fhzyu5  number of comments:   345\n",
      "fo5geh  number of comments:   269\n",
      "fpbug6  number of comments:   246\n",
      "g78qo4  number of comments:   151\n",
      "flvdic  number of comments:   335\n",
      "fyg6tm  number of comments:   184\n",
      "frr6ik  number of comments:   251\n",
      "fk5m07  number of comments:   307\n",
      "fhgnn3  number of comments:   387\n",
      "fve2wq  number of comments:   225\n",
      "fiio5o  number of comments:   336\n",
      "foqmvt  number of comments:   244\n",
      "fnkb5o  number of comments:   313\n",
      "fr66o8  number of comments:   257\n",
      "fz5oik  number of comments:   197\n",
      "fpxagz  number of comments:   265\n",
      "ft068e  number of comments:   231\n",
      "fuu28n  number of comments:   220\n",
      "g4t5ud  number of comments:   161\n",
      "g0jcbi  number of comments:   153\n",
      "fwkvfa  number of comments:   208\n",
      "fu8saj  number of comments:   223\n",
      "fxssfx  number of comments:   193\n",
      "fx6u28  number of comments:   193\n",
      "fzx3wk  number of comments:   121\n",
      "fqkk56  number of comments:   213\n",
      "fg9kfi  number of comments:   305\n",
      "ffqiyn  number of comments:   262\n",
      "fkpu59  number of comments:   265\n",
      "fgxhiy  number of comments:   219\n",
      "fcr8dy  number of comments:   286\n",
      "fcfg0w  number of comments:   235\n",
      "ff8roc  number of comments:   262\n",
      "fe9i00  number of comments:   249\n",
      "fevfr5  number of comments:   228\n",
      "fdr7u4  number of comments:   237\n",
      "fdcznm  number of comments:   255\n",
      "fb8ygf  number of comments:   256\n",
      "fbuxyx  number of comments:   216\n",
      "fa6etv  number of comments:   193\n",
      "faowou  number of comments:   219\n",
      "f9nx69  number of comments:   163\n",
      "f9az8y  number of comments:   144\n",
      "f7xqas  number of comments:   107\n",
      "f8v592  number of comments:   123\n",
      "f706aq  number of comments:   61\n",
      "f7h02k  number of comments:   61\n",
      "f8n49s  number of comments:   67\n",
      "fere6p  number of comments:   15\n",
      "fgsu67  number of comments:   9\n",
      "fgwgiz  number of comments:   4\n",
      "\n",
      "Processing time: 14.45 minutes.\n"
     ]
    }
   ],
   "source": [
    "st = time()\n",
    "\n",
    "print(\"There are\", len(discussion_ids), \"daily discussions to grab comments from.\\n\")\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for disc_id in discussion_ids:\n",
    "    disc_dict = {}      \n",
    "    \n",
    "    submission = reddit.submission(disc_id)    \n",
    "    submission.comments.replace_more(limit=0)\n",
    "    \n",
    "    print(disc_id, \" number of comments:  \", len(submission.comments))\n",
    "    if disc_id not in comment_dict.keys():\n",
    "        comment_dict[disc_id] = {}\n",
    "        \n",
    "    for user_comment in submission.comments:\n",
    "\n",
    "        if str(user_comment) not in comment_dict[disc_id].keys():\n",
    "\n",
    "            #submission.comments.replace_more(limit=0)\n",
    "            comment = user_comment.body\n",
    "            comment = comment.replace('\\n', ' ')\n",
    "            comment = comment.replace('I\\'m', 'i am').replace('i\\'m', 'i am').replace('i\\'ll', 'i will').replace('I\\'ll', 'i will')\n",
    "            comment = comment.lower()\n",
    "\n",
    "            #grab date/ time info for each comment \n",
    "            utc = submission.created_utc\n",
    "            dt_object = datetime.fromtimestamp(utc)  \n",
    "\n",
    "            #performing sentiment analysis\n",
    "            ss = sid.polarity_scores(comment)\n",
    "\n",
    "\n",
    "            token_dict = {\"comment_body\" : comment}\n",
    "            token_dict.update({\"month\":dt_object.strftime(\"%B\")})\n",
    "            token_dict.update({\"day\" : dt_object.strftime(\"%d\")})\n",
    "            token_dict.update(ss)\n",
    "            disc_dict.update({str(user_comment): token_dict})\n",
    "\n",
    "            comment_dict.update({disc_id: disc_dict})\n",
    "\n",
    "# with open(r\"/Users/AllysonEnglish/Active/Active/coronavirus_subreddit_full.json\", \"w\") as outfile: \n",
    "#     json.dump(comment_dict, outfile, indent = 4)\n",
    "    \n",
    "print(\"\\nProcessing time:\", round((time()-st)/60, 2), \"minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comment_dict['f8n49s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>fq8tliu</td>\n",
       "      <td>May</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>fq96f6i</td>\n",
       "      <td>May</td>\n",
       "      <td>10</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.8316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>fq8oonj</td>\n",
       "      <td>May</td>\n",
       "      <td>10</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.9731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>fq6hce7</td>\n",
       "      <td>May</td>\n",
       "      <td>10</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.6627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>fq67hfw</td>\n",
       "      <td>May</td>\n",
       "      <td>10</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.6126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id month date  positive  neutral  negative  compound\n",
       "0    fq8tliu   May   10     0.000    1.000     0.000    0.0000\n",
       "1    fq96f6i   May   10     0.097    0.746     0.157   -0.8316\n",
       "2    fq8oonj   May   10     0.034    0.879     0.087   -0.9731\n",
       "3    fq6hce7   May   10     0.178    0.766     0.057    0.6627\n",
       "4    fq67hfw   May   10     0.161    0.717     0.122    0.6126"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discussion_id = json_data.keys()\n",
    "\n",
    "m_date = []\n",
    "d_date = []\n",
    "negative = []\n",
    "neutral = []\n",
    "positive = []\n",
    "compound = []\n",
    "comment_id = []\n",
    "\n",
    "for k in json_data.keys():\n",
    "    \n",
    "    for y in json_data[k].keys():\n",
    "        comment_id.append(y)\n",
    "    \n",
    "    for x in json_data[k]:\n",
    "        m_date.append(json_data[k][x].get('month'))\n",
    "        d_date.append(json_data[k][x].get('day'))\n",
    "        negative.append(json_data[k][x].get('neg'))\n",
    "        neutral.append(json_data[k][x].get('neu'))\n",
    "        positive.append(json_data[k][x].get('pos'))\n",
    "        compound.append(json_data[k][x].get('compound'))\n",
    "\n",
    "    \n",
    "d = {'comment_id' : comment_id, 'month': m_date, 'date': d_date, 'positive': positive, 'neutral': neutral, 'negative': negative, 'compound': compound}\n",
    "df = pd.DataFrame(data=d)\n",
    "df = df[df.positive != 1.0000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DOM'] = df['month']+df['date']\n",
    "new_df = df.groupby('DOM').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "avrg_by_day = df.groupby('DOM').mean().reset_index()\n",
    "\n",
    "def sort_days(x):\n",
    "    if x.startswith('F'):\n",
    "        return 2\n",
    "    elif x.startswith('Mar'):\n",
    "        return 3\n",
    "    elif x.startswith('Ap'):\n",
    "        return 4\n",
    "    elif x.startswith('May'):\n",
    "        return 5\n",
    "\n",
    "avrg_by_day['month_num'] = avrg_by_day['DOM'].apply(sort_days) \n",
    "\n",
    "def day_num(x):\n",
    "    return int(x[-2:])\n",
    "\n",
    "avrg_by_day['day_num'] = avrg_by_day['DOM'].apply(day_num)\n",
    "\n",
    "avrg_by_day.sort_values(['month_num', 'day_num'], inplace = True)\n",
    "avrg_by_day.reset_index(drop=True, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month_num'] = df['DOM'].apply(sort_days)\n",
    "df['day_num'] = df['DOM'].apply(day_num)\n",
    "df.sort_values(['month_num', 'day_num'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>compound</th>\n",
       "      <th>DOM</th>\n",
       "      <th>month_num</th>\n",
       "      <th>day_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16702</td>\n",
       "      <td>fi87aru</td>\n",
       "      <td>February</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.6808</td>\n",
       "      <td>February20</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16703</td>\n",
       "      <td>fi8t8ty</td>\n",
       "      <td>February</td>\n",
       "      <td>20</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.3642</td>\n",
       "      <td>February20</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16704</td>\n",
       "      <td>fi87yil</td>\n",
       "      <td>February</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>February20</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16705</td>\n",
       "      <td>fi929rs</td>\n",
       "      <td>February</td>\n",
       "      <td>20</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.6662</td>\n",
       "      <td>February20</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16706</td>\n",
       "      <td>fi88d36</td>\n",
       "      <td>February</td>\n",
       "      <td>20</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4137</td>\n",
       "      <td>February20</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment_id     month date  positive  neutral  negative  compound  \\\n",
       "16702    fi87aru  February   20     0.000    0.663     0.337   -0.6808   \n",
       "16703    fi8t8ty  February   20     0.090    0.776     0.134   -0.3642   \n",
       "16704    fi87yil  February   20     0.000    1.000     0.000    0.0000   \n",
       "16705    fi929rs  February   20     0.063    0.937     0.000    0.6662   \n",
       "16706    fi88d36  February   20     0.084    0.916     0.000    0.4137   \n",
       "\n",
       "              DOM  month_num  day_num  \n",
       "16702  February20          2       20  \n",
       "16703  February20          2       20  \n",
       "16704  February20          2       20  \n",
       "16705  February20          2       20  \n",
       "16706  February20          2       20  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08431107039423127, 0.07916525799397124)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['negative'].mean(), df['positive'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a49443490>]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = new_df['compound']\n",
    "x = new_df.index\n",
    "\n",
    "#ploting with matplotlib\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,4))\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.scatter(x, y)\n",
    "\n",
    "\n",
    "z = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(z)\n",
    "ax.plot(x,p(x),\"r--\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workdesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating csv with new inputs\n",
    "\n",
    "old_df = pd.read_csv(r'/Users/AllysonEnglish/Active/Active/sentiment_analysis_draft1.csv')\n",
    "to_add = df[~df['discussion_id'].isin(old_df['discussion_id'])]\n",
    "to_add.to_csv(r'/Users/AllysonEnglish/Active/Active/sentiment_analysis_draft1.csv', mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why is this marked as positive?\n",
    "comment_dict['fq3a3nl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_tokens = []\n",
    "\n",
    "submission = reddit.submission(id=final_id)\n",
    "for top_level_comment in submission.comments:\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    comment = top_level_comment.body\n",
    "    comment = comment.replace('\\n', ' ')\n",
    "    try:\n",
    "        tagged = nltk.pos_tag(comment.split(' '))\n",
    "        tagged_tokens.append(tagged)\n",
    "    except IndexError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = 0\n",
    "adjectives = 0\n",
    "\n",
    "for pair in tagged_tokens:\n",
    "    for tag in pair:\n",
    "        if tag[1] == 'JJ':\n",
    "            adjectives += 1\n",
    "        elif tag[1] == 'NN':\n",
    "            nouns += 1\n",
    "        elif tag[1] == 'NNS':\n",
    "            nouns += 1\n",
    "    \n",
    "\n",
    "print('There are', nouns, 'nouns in this text.')\n",
    "print('There are', adjectives, 'adjectives in this text.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for y in tagged_tokens for x in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_tokens = []\n",
    "\n",
    "submission = reddit.submission(id=final_id)\n",
    "for top_level_comment in submission.comments:\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    reddit_tokens.append(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_tokens = []\n",
    "\n",
    "for token in reddit_tokens:\n",
    "    try:\n",
    "        tagged = nltk.pos_tag(token.split(' '))\n",
    "        tagged_tokens.append(tagged)\n",
    "    except IndexError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_tokens[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toast = sid.polarity_scores(bread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bread = reddit_tokens[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheese = ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid.score_valence(cheese, bread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "for comment in reddit_tokens:\n",
    "    print(comment)\n",
    "    ss = sid.polarity_scores(comment)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}%, '.format(k, round(ss[k]*100, 2)), end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagged_comments = nltk.pos_tag(comment.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [item.replace('.','') for item in wordlist]\n",
    "#     wordlist = [item.replace(':','') for item in wordlist]\n",
    "#     wordlist = [item.replace('-','') for item in wordlist]\n",
    "#     wordlist = [item.replace('?','') for item in wordlist]\n",
    "#     wordlist = [item.replace('!','') for item in wordlist]\n",
    "#     wordlist = [item.replace('*','') for item in wordlist]\n",
    "#     wordlist = [item.replace(',','') for item in wordlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(comment.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_tokens = []\n",
    "\n",
    "submission = reddit.submission(id=final_id)\n",
    "for top_level_comment in submission.comments:\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    comment = top_level_comment.body\n",
    "    comment.replace('\\n', ' ')\n",
    "    try:\n",
    "        tagged = nltk.pos_tag(comment.split(' '))\n",
    "        tagged_tokens.append(tagged)\n",
    "    except IndexError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(submission.comments.body.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords = []\n",
    "submission.comments.replace_more(limit=0)\n",
    "for top_level_comment in submission.comments:\n",
    "    wordlist = top_level_comment.body.split()\n",
    "    wordlist = [item.replace('.','') for item in wordlist]\n",
    "    wordlist = [item.replace(':','') for item in wordlist]\n",
    "    wordlist = [item.replace('-','') for item in wordlist]\n",
    "    wordlist = [item.replace('?','') for item in wordlist]\n",
    "    wordlist = [item.replace('!','') for item in wordlist]\n",
    "    wordlist = [item.replace('*','') for item in wordlist]\n",
    "    wordlist = [item.replace(',','') for item in wordlist]\n",
    "    wordlist = [item.replace('(','').replace(')','') for item in wordlist]\n",
    "    allwords.extend(wordlist)\n",
    "    \n",
    "print(allwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = \"allys'on\" \"aren't\"\n",
    "item.find(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting = 'sup homie {}!'\n",
    "names = ['bob', 'joe', 'ally']\n",
    "\n",
    "for name in names:\n",
    "    print(greeting.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"n't\":\n",
    "    \"n't\"\n",
    "else:\n",
    "    item.replace(\"''\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.replace(\"'\", '').replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords = []\n",
    "submission.comments.replace_more(limit=0)\n",
    "for top_level_comment in submission.comments:\n",
    "    wordlist = top_level_comment.body.split()\n",
    "    wordlist = [item.replace('.','') for item in wordlist]\n",
    "    wordlist = [item.replace(':','') for item in wordlist]\n",
    "    wordlist = [item.replace('-','') for item in wordlist]\n",
    "    wordlist = [item.replace('?','') for item in wordlist]\n",
    "    wordlist = [item.replace('!','') for item in wordlist]\n",
    "    wordlist = [item.replace('*','') for item in wordlist]\n",
    "    wordlist = [item.replace(',','') for item in wordlist]\n",
    "    wordlist = [item.replace('(','').replace(')','') for item in wordlist]\n",
    "    allwords.extend(wordlist)\n",
    "    \n",
    "print(allwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in allwords:\n",
    "    count = frequency.get(word,0)\n",
    "    frequency[word] = count + 1\n",
    "     \n",
    "frequency_list = frequency.keys()\n",
    " \n",
    "for words in frequency_list:\n",
    "    print (words, frequency [words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = {}\n",
    "for w in wordlist:\n",
    "    count= frequency.get(w,0)\n",
    "    frequency[w]= count + 1\n",
    "    wordfreq.append(wordlist.count(w))\n",
    "\n",
    "frequency_list = frequency.keys()\n",
    "\n",
    "for w in frequency_list:\n",
    "    print (w, frequency[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from praw.models import MoreComments\n",
    "for top_level_comment in submission.comments:\n",
    "    if isinstance(top_level_comment, MoreComments):\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.comments.replace_more(limit=None)\n",
    "comment_queue = submission.comments[:]  # Seed with top-level\n",
    "while comment_queue:\n",
    "    comment = comment_queue.pop(0)\n",
    "    print(comment.body)\n",
    "    comment_queue.extend(comment.replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.comments.replace_more(limit=None)\n",
    "for comment in submission.comments.list():\n",
    "    print(comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordstring = top_level_comment.body\n",
    "for top_level_comment in submission.comments:\n",
    "    if isinstance(top_level_comment, MoreComments):\n",
    "        continue"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq = []\n",
    "for w in wordlist:\n",
    "    wordfreq.append(wordlist.count(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordstring = 'it was the best of times it was the worst of times '\n",
    "wordstring += 'it was the age of wisdom it was the age of foolishness'\n",
    "\n",
    "wordlist = wordstring.split()\n",
    "\n",
    "wordfreq = []\n",
    "for w in wordlist:\n",
    "    wordfreq.append(wordlist.count(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lotsofcomments = post.comments.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onecomment = lotsofcomments[0]\n",
    "onecomment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onecomment.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = reddit.submission(id='3g1jfi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for top_level_comment in submission.comments:\n",
    "    print(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_text = top_level_comment.body\n",
    "total_analysis = total_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral\n",
    "positive \n",
    "negative \n",
    "compound \n",
    "token_dict \n",
    "score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blob = TextBlob(\"This excellent practice sentance is the best one to ues due to it's perfectly written syntax and great message.\")\n",
    "# for np in blob.noun_phrases:\n",
    "#     print(np)\n",
    "\n",
    "# for words, tags in blob.tags:\n",
    "#     print(words, tags)\n",
    "    \n",
    "# for ngram in blob.ngrams(3):\n",
    "#     print(ngram)\n",
    "\n",
    "# blob.sentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(comment_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_blob_dict = {}\n",
    "\n",
    "for each_token in tokens:\n",
    "    analysis_tok = TextBlob(each_token)\n",
    "    txt_blob_dict.update({each_token: analysis_tok.sentiment})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in tokens:\n",
    "    tok.replace(\"\\n\",\"\")\n",
    "    print(tok)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_dict['fq67hfw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid.polarity_scores(comment_dict['fq67hfw'].capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for words in TextBlob(comment_dict['fq67hfw']).ngrams(5):\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_score = TextBlob(comment_dict['fq67hfw']).sentiment\n",
    "tb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.replace(\"I\\'m\",\"I am\").replace(\"\\n\",\" \").replace(\"i\\'ll\",\"i will\").replace(\"i\\'m\",\"i will\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid.polarity_scores(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_score = TextBlob(test).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = NaiveBayesClassifier.train\n",
    "\n",
    "daily_discussion = list(subreddit.hot(limit=1))\n",
    "discussion_id = (str(daily_discussion))\n",
    "final_id = discussion_id.replace(\"[Submission(id='\",\"\").replace(\"')]\",\"\")\n",
    "print(final_id)\n",
    "\n",
    "submission = reddit.submission(id=final_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for running textblob.\n",
    "\n",
    "\n",
    "# blob = TextBlob(\"This excellent practice sentance is the best one to ues due to it's perfectly written syntax and great message.\")\n",
    "# for np in blob.noun_phrases:\n",
    "#     print(np)\n",
    "\n",
    "# for words, tags in blob.tags:\n",
    "#     print(words, tags)\n",
    "    \n",
    "# for ngram in blob.ngrams(3):\n",
    "#     print(ngram)\n",
    "\n",
    "# blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ploting with matplotlib\n",
    "\n",
    "# plt.plot(y, x)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
